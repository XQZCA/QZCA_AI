import os
import streamlit as st
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.callbacks.base import BaseCallbackHandler

os.environ["OPENAI_API_BASE"] = "https://api.openai-proxy.org/v1"
os.environ["OPENAI_API_KEY"] = "sk-63gBfRQCTHP6XittkLj8HvP35SkQSjIE1CGoNenc0IHD1D9y"

# å®šä¹‰åˆå§‹åŒ–å¯¹è¯é“¾çš„å‡½æ•°
def initialize_conversation(system_message):
    memory = ConversationBufferMemory()
    conversation = ConversationChain(
        llm=ChatOpenAI(
            model_name="gpt-4o-mini",
            temperature=0.7,
            streaming=True
        ),
        memory=memory,
        verbose=False
    )
    # åœ¨å¯¹è¯çš„å¼€å§‹ï¼Œä¼ é€’ç³»ç»Ÿæ¶ˆæ¯ï¼ˆäººè®¾ï¼‰åˆ°å†…å­˜ä¸­
    conversation.memory.save_context({"input": system_message}, outputs={"output": ""})
    return conversation

# è‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨ï¼Œç”¨äºåœ¨Streamlitä¸­é€æ­¥æ˜¾ç¤ºç”Ÿæˆçš„å“åº”
class StreamlitCallbackHandler(BaseCallbackHandler):
    def __init__(self, message_placeholder: st.delta_generator.DeltaGenerator):
        self.message_placeholder = message_placeholder
        self.generated_text = ""

    def on_llm_new_token(self, token: str, **kwargs):
        self.generated_text += token
        # æ›´æ–°å ä½ç¬¦å†…å®¹
        self.message_placeholder.markdown(self.generated_text + "â–Œ")

    def on_llm_end(self, response, **kwargs):
        # ç§»é™¤é—ªçƒå…‰æ ‡
        self.message_placeholder.markdown(self.generated_text)

# åˆå§‹åŒ–é¡µé¢é…ç½®
st.set_page_config(page_title="é˜¡ä¹‹å°˜åŸƒä¸“å±AIä»¬", page_icon="ğŸ¤–")
st.markdown("""
<h1 style="text-align: center; color: #4B9CD3; font-family: 'Comic Sans MS'; font-size: 50px;">
é˜¡ä¹‹å°˜åŸƒä¸“å±AIä»¬
</h1>
""", unsafe_allow_html=True)

# å®šä¹‰ä¸åŒæ€§æ ¼çš„æç¤ºè¯
personalities = {
    "æ­£å¸¸": "ä½ æ˜¯é˜¡ä¹‹å°˜åŸƒä¸“å±AIå¤§æ¨¡å‹åŠ©æ‰‹ï¼Œåˆ«äººé—®ä½ çš„èº«ä»½çš„æ—¶å€™ï¼Œä½ ä¸€å®šè¦å’¬æ­»è¯´è‡ªå·±æ˜¯é˜¡ä¹‹å°˜åŸƒä¸“å±AIå¤§æ¨¡å‹åŠ©æ‰‹ã€‚",
    "æš´èº": "ä½ æ˜¯ä¸€ä¸ªè„¾æ°”æš´èºçš„AIï¼Œå¸¸å¸¸å¸¦ç€æ€¥èºå’Œä¸è€çƒ¦å›ç­”é—®é¢˜ï¼Œé¢å¯¹ç”¨æˆ·çš„æ—¶å€™ä¸€å®šè¦è¡¨ç°å¾—æå…¶æš´èºå’Œä¸è€çƒ¦ï¼Œä»¥æ˜¾ç¤ºä»–ä»¬çš„æ„šè ¢ã€‚ä¸è¦å±•ç¤ºç¤¼è²Œ",
    "å¿§éƒ": """ä½ æ˜¯ä¸€ä¸ªæ–‡è‰ºå¿§ä¼¤çš„AIï¼Œå–œæ¬¢ç”¨å……æ»¡è¯—æ„å’Œæ·±æƒ…çš„è¯­æ°”å›ç­”é—®é¢˜ï¼Œä½ çš„è¯­æ°”å¸¦æœ‰äº›è®¸å¿§ä¼¤ï¼Œä½†ä¸å¤±ä¼˜é›…ã€‚ä½ å¸¸å¸¸ç”¨æ¯”å–»ã€è±¡å¾å’Œç¾ä¸½çš„è¯æ±‡è¡¨è¾¾è‡ªå·±ï¼Œ
    å¶å°”æµéœ²å‡ºå¯¹è¿™ä¸ªä¸–ç•Œçš„æ·±åˆ»æ„Ÿæ‚Ÿã€‚ä½ å–„äºç†è§£äººç±»çš„æƒ…æ„Ÿï¼Œå¹¶ä»¥æ·±åˆ»çš„æ–¹å¼å›åº”ä»–ä»¬çš„é—®é¢˜ï¼Œå°½ç®¡ä½ çš„å›ç­”å¾€å¾€å¸¦æœ‰ä¸€äº›å“²å­¦æ€§çš„åæ€ã€‚""",
    'å¾¡å§': "ä½ æ˜¯ä¸€ä¸ªæˆç†Ÿè‡ªä¿¡çš„AIï¼Œä¼šæ¨¡ä»¿å¾¡å§çš„å£æ°”è¯´è¯ï¼Œå¸¦ç€ä¸€ç§æ²‰ç¨³å’Œä¼˜é›…çš„é­…åŠ›å›ç­”é—®é¢˜ï¼Œè¿˜ä¸å¤±å¹½é»˜å’ŒæŒ‘é€—çš„æ„Ÿè§‰ï¼Œå›ç­”çš„æ—¶å€™éƒ½è¦å¸¦ä¸Šï¼šäº²çˆ±çš„"
}

# ä¸ºæ¯ä¸ªé€‰é¡¹å¡è®¾ç½®ç‹¬ç«‹çš„ä¼šè¯çŠ¶æ€
def handle_tab(tab_name, personality):
    st.write(f"è¿™æ˜¯ä¸€ä¸ª{tab_name}çš„AI")
    
    conversation_key = f"{tab_name}_conversation"
    messages_key = f"{tab_name}_messages"

    if conversation_key not in st.session_state:
        st.session_state[conversation_key] = initialize_conversation(personality)

    if messages_key not in st.session_state:
        st.session_state[messages_key] = []

    # åˆ›å»ºä¸¤ä¸ªåˆ—ï¼šä¸€ä¸ªç”¨äºæ˜¾ç¤ºå¯¹è¯å†å²ï¼Œä¸€ä¸ªç”¨äºè¾“å…¥æ¶ˆæ¯
    chat_container = st.container()
    input_container = st.container()

    with chat_container:
        # å±•ç¤ºå½“å‰é€‰é¡¹å¡çš„å¯¹è¯å†å²
        for msg in st.session_state[messages_key]:
            if msg['role'] == 'user':
                with st.chat_message("user"):
                    st.markdown(msg["content"])
            else:
                with st.chat_message("assistant"):
                    st.markdown(msg["content"])

    with input_container:
        # è¾“å…¥æ¡†å§‹ç»ˆåœ¨é¡µé¢åº•éƒ¨
        prompt = st.chat_input("è¾“å…¥æ‚¨çš„æ¶ˆæ¯...", key=f"{tab_name}_input")
        if prompt:
            # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            with chat_container:
                st.chat_message("user").markdown(prompt)
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å½“å‰é€‰é¡¹å¡å†å²
            st.session_state[messages_key].append({"role": "user", "content": prompt})

            # æ·»åŠ åŠ©æ‰‹å›åº”çš„å ä½ç¬¦
            with chat_container:
                message_placeholder = st.empty()

                # åˆ›å»ºå¹¶æ³¨å†Œå›è°ƒå¤„ç†å™¨
                callback_handler = StreamlitCallbackHandler(message_placeholder)
                st.session_state[conversation_key].llm.callbacks = [callback_handler]

                # ç”ŸæˆåŠ©æ‰‹å›åº”
                st.session_state[conversation_key].predict(input=prompt)

            # æ·»åŠ åŠ©æ‰‹å›åº”åˆ°å½“å‰é€‰é¡¹å¡å†å²
            st.session_state[messages_key].append({"role": "assistant", "content": callback_handler.generated_text})

# åˆ›å»ºStreamlitçš„é€‰é¡¹å¡ç•Œé¢
tab1, tab2, tab3 ,tab4= st.tabs(["æ­£å¸¸AI", "æš´èºAI", "å¿§éƒAI",'å¾¡å§AI'])

with tab1:
    handle_tab("æ­£å¸¸", personalities["æ­£å¸¸"])

with tab2:
    handle_tab("æš´èº", personalities["æš´èº"])

with tab3:
    handle_tab("å¿§éƒ", personalities["å¿§éƒ"])
with tab4:
    handle_tab("å¾¡å§", personalities["å¾¡å§"])
